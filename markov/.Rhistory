print(ep_list[ep_num])
new_url <- paste(base_url, ep_list[ep_num])
print(new_url)
}
pastee
?paste
for(ep_num in 1:length(ep_list)){
base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
new_url <- paste(base_url, ep_list[ep_num], sep="")
print(new_url)
}
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
new_url <- paste(base_url, ep_list[ep_num], sep="")
quotes <- rbind(quotes, pull_quotes("new_url"))
}
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
new_url <- paste(base_url, ep_list[ep_num], sep="")
quotes <- rbind(quotes, pull_quotes(new_url))
}
## frequency table of characters
quotes[, .N, by = name]
## frequency table of characters
quotes[, .N, by = name][order(-name)]
## frequency table of characters
quotes[, .N, by = name][order(name)]
## frequency table of characters
quotes[, .N, by = name][order(-V1)]
## frequency table of characters
quotes[, .N, by = name][order(-name)]
## frequency table of characters
quotes[, .N, by = name]
test <- pull_quotes("http://atla.avatarspirit.net/transcripts.php?num=101")
View(test)
test <- pull_quotes("http://atla.avatarspirit.net/transcripts.php?num=102")
url1 <- "http://atla.avatarspirit.net/transcripts.php?num=102"
webpage <- read_html(url1)
all <- webpage %>%
html_nodes("blockquote") %>%
html_text()
all
#remove all text in parenthesis & brackets
all <- gsub("\\(.*?\\)", "", all)
all <- gsub("\\[.*?\\]", "", all)
## remove all text before "Act I" (metadata)
all <- sub("Act I","REMOVEME", all)
all <- gsub(".*REMOVEME", " ", all)
## remove "Act II" etc.
#all <- gsub("Act I", " ", all)
all <- gsub("Act II", " ", all)
all <- gsub("Act III", " ", all)
all <- gsub("Act IV", " ", all)
all
# remove quotes (e.g. "Master Katara" -> Master Katara)
all <- gsub("\\\"", "", all)
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[[:punct:]])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?=[[:punct:]])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[[:punct:]])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[\\: | \\. | \\? | \\! | \\-])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[\\: | \\. | \\? | \\!])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[\\: | \\.])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-|\\—])", perl=T))
lines
## split lines on all punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–])", perl=T))
lines
library(rvest)
library(data.table)
pull_quotes <- function(URL) {
webpage <- read_html(URL)
all <- webpage %>%
html_nodes("blockquote") %>%
html_text()
#remove all text in parenthesis & brackets
all <- gsub("\\(.*?\\)", "", all)
all <- gsub("\\[.*?\\]", "", all)
## remove all text before "Act I" (metadata)
all <- sub("Act I","REMOVEME", all)
all <- gsub(".*REMOVEME", " ", all)
## remove "Act II" etc.
#all <- gsub("Act I", " ", all)
all <- gsub("Act II", " ", all)
all <- gsub("Act III", " ", all)
all <- gsub("Act IV", " ", all)
# remove quotes (e.g. "Master Katara" -> Master Katara)
all <- gsub("\\\"", "", all)
## split lines on selected punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–])", perl=T))
## lines with : -> character name
## all other lines -> most recent character's name's lines
quotes <- data.table(name=character(), quote=character())
current_line <- nrow(quotes)
for(i in 1:length(lines)){
if(grepl(":", lines[i])){ # make a new line
quotes <- rbind(quotes, data.table(name = gsub("\\:|\\s", "", lines[i]), quote="")) # add character name
current_line <- current_line + 1 #update line counter
}
else{
quotes[current_line,"quote"] <- paste(quotes[current_line,"quote"], lines[i])
}
}
return(quotes)
}
test <- pull_quotes("http://atla.avatarspirit.net/transcripts.php?num=102")
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
new_url <- paste(base_url, ep_list[ep_num], sep="")
quotes <- rbind(quotes, pull_quotes(new_url))
print(paste("Done with Episode ", ep_list[ep_num]))
}
## frequency table of characters
quotes[, .N, by = name]
## frequency table of characters
quotes[, .N, by = name][order(-N)]
test <- pull_quotes("http://atla.avatarspirit.net/transcripts.php?num=108")
url1 <- "http://atla.avatarspirit.net/transcripts.php?num=108"
webpage <- read_html(url1)
all <- webpage %>%
html_nodes("blockquote") %>%
html_text()
#remove all text in parenthesis & brackets
all <- gsub("\\(.*?\\)", "", all)
all <- gsub("\\[.*?\\]", "", all)
## remove all text before "Act I" (metadata)
all <- sub("Act I","REMOVEME", all)
all <- gsub(".*REMOVEME", " ", all)
## remove "Act II" etc.
#all <- gsub("Act I", " ", all)
all <- gsub("Act III", " ", all)
all <- gsub("Act II", " ", all)
all <- gsub("Act IV", " ", all)
# remove quotes (e.g. "Master Katara" -> Master Katara)
all <- gsub("\\\"", "", all)
## split lines on selected punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–])", perl=T))
all
## frequency table of characters
quotes[, .N, by = name][order(-N)]
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
new_url <- paste(base_url, ep_list[ep_num], sep="")
quotes <- rbind(quotes, pull_quotes(new_url))
print(paste("Done with Episode ", ep_list[ep_num]))
}
## frequency table of characters
quotes[, .N, by = name][order(-N)]
## remove pucntuation from names
quotes <- gsub("[[:punct:]]", "", quotes[1,])
## frequency table of characters
quotes[, .N, by = name][order(-N)]
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
new_url <- paste(base_url, ep_list[ep_num], sep="")
quotes <- rbind(quotes, pull_quotes(new_url))
print(paste("Done with Episode ", ep_list[ep_num]))
}
save(quotes,file="quotes.Rda")
## remove pucntuation from names
quotes <- gsub("[[:punct:]]", "", quotes[, 1])
## frequency table of characters
quotes[, .N, by = name][order(-N)]
## remove pucntuation from names
load("quotes.Rda")
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
new_url <- paste(base_url, ep_list[ep_num], sep="")
quotes <- rbind(quotes, pull_quotes(new_url))
print(paste("Done with Episode ", ep_list[ep_num]))
}
save(quotes,file="quotes_file.Rda")
## remove punctuation from names
quotes[, 1] <- gsub("[[:punct:]]", "", quotes[, 1])
## frequency table of characters
quotes[, .N, by = name][order(-N)]
quotes <- load("quotes_file.Rda")
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
new_url <- paste(base_url, ep_list[ep_num], sep="")
quotes <- rbind(quotes, pull_quotes(new_url))
print(paste("Done with Episode ", ep_list[ep_num]))
}
## frequency table of characters
quotes[, .N, by = name][order(-N)]
## still some errors, but just dropping those lines
keep <- c("Aang", "Sokka", "Katara", "Zuko", "Toph", "Iroh")
## still some errors, but just dropping those lines
keep <- c("Aang", "Sokka", "Katara", "Zuko", "Toph", "Iroh")
new <- quotes[quotes$name %in% keep, ]
View(new)
top_quotes <- quotes[quotes$name %in% keep, ]
View(top_quotes)
shiny::runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
?html
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
load("/Users/kira.tebbeibm.com/Documents/Side Projects/markov/quotes_file.Rda")
runApp('Documents/Side Projects/markov/markov')
quotes2 <- load("/Users/kira.tebbeibm.com/Documents/Side Projects/markov/quotes_file.Rda")
View(quotes)
View(top_quotes)
write.table(top_quotes, "top_quotes.csv")
top_quotes2 <- read.table("top_quotes.csv")
View(top_quotes2)
class(top_quotes2)
top_quotes2 <- fread("top_quotes.csv")
top_quotes2 <- fread("top_quotes.csv", header=T)
top_quotes2 <- fread("top_quotes.csv", header=T, fill=T)
top_quotes2 <- fread("top_quotes.csv", header=T, fill=T, data.table=T)
top_quotes2 <- fread("top_quotes.csv", fill=T, data.table=T)
top_quotes2 <- fread("top_quotes.csv", header=T, data.table=T)
top_quotes2 <- fread("top_quotes.csv", header=T, data.table=T, select=c(1,2))
top_quotes2 <- fread("top_quotes.csv", header=T, data.table=T, fill=T)
top_quotes2 <- fread("top_quotes.csv", header=T, data.table=T, row.names=NULL)
top_quotes2 <- fread("top_quotes.csv", header=T, data.table=T, col.names=c("name", "quote"))
runApp('Documents/Side Projects/markov/markov')
top_quotes2 <- fread("top_quotes.csv", header=T, fill=T, data.table=T, col.names=c("name", "quote"))
runApp('Documents/Side Projects/markov/markov')
top_quotes2 <- fread("top_quotes.csv", header=T, fill=T, data.table=T, col.names=c("drop", "name", "quote"))
top_quotes2 <- top_quotes2[,-drop]
runApp('Documents/Side Projects/markov/markov')
top_quotes2 <- top_quotes2[,-1]
class(top_quotes2)
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
runApp('Documents/Side Projects/markov/markov')
quotes2 <- fread("top_quotes.csv", header=T, fill=T, data.table=T, col.names=c("drop", "name", "quote"))
quotes3 <- fread("top_quotes.csv", header=T, fill=T, data.table=T, col.names=c("drop", "name", "quote"))
setwd("~/Documents/Side Projects/markov/markov")
quotes3 <- fread("top_quotes.csv", header=T, fill=T, data.table=T, col.names=c("drop", "name", "quote"))
View(quotes3)
quotes3 <- quotes3[,-1]
quotes3[1,2]
paste(quotes3[1,2])
quotes3["name" == "Aang"]
install.package("dplyr")
install.packages("dplyr")
library(dplyr)
quotes3 %>% filter(name == "Aang")
sample(quotes3 %>% filter(name == "Aang"),1)
quotes3 %>% filter(name == "Aang")
quotes3 %>% filter(name == "Aang")[1]
head(quotes3 %>% filter(name == "Aang"))
(quotes3 %>% filter(name == "Aang")[1,]
stringToPrint <- c(stringToPrint,"<b>", names[i], ": </b>", "<br>")
stringToPrint <- c(stringToPrint, quotes[1,2])
}
}
HTML(stringToPrint)
})
(quotes3 %>% filter(name == "Aang"))[1]
(quotes3 %>% filter(name == "Aang"))[1,1]
(quotes3 %>% filter(name == "Aang"))[1,2]
sample((quotes3 %>% filter(name == "Aang"))[,2], 1)
sample((quotes3 %>% filter(name == "Aang"))[,2], 1)
sample((quotes3 %>% filter(name == "Aang"))[,2], 1)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
## making trigram
aangQuotes <- quotes %>% filter(name == "Aang")
View(aangQuotes)
aangTrigram <- data.table(w1=character(), w2=character(), w3=character(), counts=numeric())
View(aangTrigram)
?gsub
strsplit(aangQuotes[2,11],".")
aangQuotes[2,11]
strsplit(aangQuotes[11,2],".")
## replacing ellipses
gsub("\\.\\.\\.|\\.\\.\\.\\.", " PAUSE ",aangQuotes)
## replacing ellipses
gsub("\\.\\.\\.|\\.\\.\\.\\.", " PAUSE ", aangQuotes[,2])
## replacing ellipses
gsub("\\. \\. \\. |\\. \\. \\. \\. ", " PAUSE ", aangQuotes[,2])
## replacing ellipses
gsub("\\. \\. \\. |\\. \\. \\. \\. |\\. \\. \\.", " PAUSE ", aangQuotes[,2])
## replacing ellipses
trimws(gsub("\\. \\. \\. |\\. \\. \\. \\. |\\. \\. \\.", " PAUSE ", aangQuotes[,2]))
## replacing ellipses
aangQuotes[,2] <- trimws(gsub("\\. \\. \\. |\\. \\. \\. \\. |\\. \\. \\.", " PAUSE ", aangQuotes[,2]))
nrow(aangQuotes)
?strsplit
## split into tokens (words, all punctuation except ')
tokens <-
strsplit(aangQuotes[1,2], "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–])")
## split into tokens (words, all punctuation except ')
tokens <-
strsplit(aangQuotes[1,2], "\\:|\\.|\\?|\\!|\\-|\\—|\\–")
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "\\:|\\.|\\?|\\!|\\-|\\—|\\–")
## split into tokens (words, all punctuation except ')
unlist(strsplit(aangQuotes[1,2], "\\:|\\.|\\?|\\!|\\-|\\—|\\–\\ "))
strsplit(aangQuotes[1,2], " ")
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "\\:|\\.|\\?|\\!|\\-|\\—|\\–\\ ")
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "\\:|\\.|\\?|\\!|\\-|\\—|\\–| ")
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–| ])")
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "\\:|\\.|\\?|\\!|\\-|\\—|\\–| ")
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=\\:|\\.|\\?|\\!|\\-|\\—|\\–| )")
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=\\:|\\.|\\?|\\!|\\-|\\—|\\–| )", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=\\.|\\?|\\!|\\-|\\—|\\–| )", perl=T)
strsplit(aangQuotes[1,2], ".")
## split into tokens (words, all punctuation except ')
trimws(strsplit(aangQuotes[1,2], "(?<=\\.|\\?|\\!|\\-|\\—|\\–| )", perl=T))
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=\\.|\\?|\\!|\\-|\\—|\\–| )", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=\\.|\\,|\\?|\\!|\\-|\\—|\\–| )", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=\\.|\\,|\\?|\\!|\\-|\\—|\\–| )", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "\\.|\\,|\\?|\\!|\\-|\\—|\\–| ", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "[\\.|\\,|\\?|\\!|\\-|\\—|\\–| ]", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=[\\.|\\,|\\?|\\!|\\-|\\—|\\–| ])", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=[\.|\\,|\\?|\\!|\\-|\\—|\\–| ])", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=[.|\\,|\\?|\\!|\\-|\\—|\\–| ])", perl=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=[\\.|\\,|\\?|\\!|\\-|\\—|\\–| ])", perl=T, fixed=T)
## split into tokens (words, all punctuation except ')
strsplit(aangQuotes[1,2], "(?<=[\\.|\\,|\\?|\\!|\\-|\\—|\\–| ])", perl=T)
aangQuotes[1,2]
strsplit(aangQuotes[1,2], "[.]")
strsplit(aangQuotes[1,2], "(?<=[.])")
strsplit(aangQuotes[1,2], "(?<=[\\.])")
strsplit(aangQuotes[1,2], "(?=[\\.])")
strsplit(aangQuotes[1,2], "\\.")
strsplit(aangQuotes[1,2], "(?<=[.,?!-—– ])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[\.,?!-—– ])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[\\.,?!-—– ])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[,?!-—– ])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[,?!-—– ])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[,?!-—–])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[?!-—–])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[,|?|!|-|—|–| ])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[,|?|!|-|—|–| ])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[.])")
strsplit(aangQuotes[1,2], "(?<=[.])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[\\.])", perl=T)
strsplit(aangQuotes[1,2], "(?<=\\.)", perl=T)
strsplit(aangQuotes[1,2], "?<=[\\.]", perl=T)
strsplit(aangQuotes[1,2], "?<=[\\.]")
strsplit(aangQuotes[1,2], "(?<=[\\.])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[ ])", perl=T)
strsplit(aangQuotes[1,2], "(?<=[ |\\.])", perl=T)
strsplit("hi.evan", "(?<=[ |\\.])", perl=T)
strsplit("hi.evan", "(?<=[\\.])", perl=T)
strsplit("h..evan", "(?<=[\\.])", perl=T)
trimws(gsub("\\.=", " PERIODEND ", aangQuotes[,2]))
trimws(gsub("\\.", " PERIODEND ", aangQuotes[,2]))
trimws(gsub("\\,", " CCOMMA ", aangQuotes[,2]))
trimws(gsub("\\?", " QQUESTION ", aangQuotes[,2]))
trimws(gsub("\\-|\\—|\\–", " DDASH ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\.", " PPERIOD ", aangQuotes[,2]))
## making trigram
aangQuotes <- quotes %>% filter(name == "Aang")
aangQuotes[,2] <- trimws(gsub("\\. \\. \\. |\\. \\. \\. \\. |\\. \\. \\.", " PPAUSE ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\.", " PPERIOD ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\,", " CCOMMA ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\?", " QQUESTION ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\1", " EEXCLAMATION ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\!", " EEXCLAMATION ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\-|\\—|\\–", " DDASH ", aangQuotes[,2]))
aangQuotes <- quotes %>% filter(name == "Aang")
## replacing ellipses & other punctuation
aangQuotes[,2] <- trimws(gsub("\\. \\. \\. |\\. \\. \\. \\. |\\. \\. \\.", " PPAUSE ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\.", " PPERIOD ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\,", " CCOMMA ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\?", " QQUESTION ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\!", " EEXCLAMATION ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\-|\\—|\\–", " DDASH ", aangQuotes[,2]))
## making trigram
aangQuotes <- quotes %>% filter(name == "Aang")
## replacing ellipses & other punctuation
aangQuotes[,2] <- trimws(gsub("\\. \\. \\. |\\. \\. \\. \\. |\\. \\. \\.", " PPAUSE ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\.", " PPERIOD ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\,", " CCOMMA ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\?", " QQUESTION ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\!", " EEXCLAMATION ", aangQuotes[,2]))
aangQuotes[,2] <- trimws(gsub("\\-|\\—|\\–", " DDASH ", aangQuotes[,2]))
## split into tokens
strsplit(aangQuotes[1,2], " ", perl=T)
aangTrigram[1,] <- c(tokens[1], tokens[2], tokens[3], 1)
aangTrigram <- rbind(aangTrigram, tokens[1], tokens[2], tokens[3], 1)
aangTrigram <- rbind(aangTrigram, data.table(w1 = tokens[1], w2 = tokens[2], w3 = tokens[3], counts = 1))
## split into tokens
tokens <- strsplit(aangQuotes[1,2], " ", perl=T)
View(tokens)
tokens
unlist(tokens)
## split into tokens
tokens <- unlist(strsplit(aangQuotes[1,2], " ", perl=T))
aangTrigram <- rbind(aangTrigram, data.table(w1 = tokens[1], w2 = tokens[2], w3 = tokens[3], counts = 1))
min(length(aangQuotes[,2]))
## split into tokens
tokens <- unlist(strsplit(aangQuotes[1,2], " ", perl=T))
## loop through tokens
## add SSTART and EEND
tokens <- c("SSTART", "SSTART", tokens, "EEND")
tokens
for(j in 1:length(tokens)-2){
aangTrigram <- rbind(aangTrigram, data.table(w1 = tokens[j], w2 = tokens[j+1], w3 = tokens[j+2], counts = 1))
}
tokens
tokens[4]
for(j in 1:(length(tokens)-2)){
aangTrigram <- rbind(aangTrigram, data.table(w1 = tokens[j], w2 = tokens[j+1], w3 = tokens[j+2], counts = 1))
}
?data.table
