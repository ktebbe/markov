---
title: "TV dialogue markov model"
output: html_notebook
---

First we will scrape dialogue from Avatar: The Last Airbender (ATLA) from the website AvatarSpirit.net

Scripts from here - http://www.simplyscripts.com/tv_all.html

```{r}
## trying rvest library
library(rvest)
library(data.table)  
ep_list <- c(101:120, 201:220, 301:321)

url1 <- "http://atla.avatarspirit.net/transcripts.php?num=108"
webpage <- read_html(url1)

all <- webpage %>% 
  html_nodes("blockquote") %>%
  html_text()

#remove all text in parenthesis & brackets
all <- gsub("\\(.*?\\)", "", all)
all <- gsub("\\[.*?\\]", "", all)

## remove all text before "Act I" (metadata)
all <- sub("Act I","REMOVEME", all)
all <- gsub(".*REMOVEME", " ", all)

## remove "Act II" etc.
#all <- gsub("Act I", " ", all)
all <- gsub("Act III", " ", all)
all <- gsub("Act II", " ", all)
all <- gsub("Act IV", " ", all)

# remove quotes (e.g. "Master Katara" -> Master Katara)
all <- gsub("\\\"", "", all)

## split lines on selected punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–])", perl=T))

## lines with : -> character name
## all other lines -> most recent character's name's lines
quotes <- data.table(name=character(), quote=character())

current_line <- nrow(quotes)
for(i in 1:length(lines)){
  if(grepl(":", lines[i])){ # make a new line
    quotes <- rbind(quotes, data.table(name = gsub("\\:|\\s", "", lines[i]), quote="")) # add character name
    current_line <- current_line + 1 #update line counter
  }
  else{
    quotes[current_line,"quote"] <- paste(quotes[current_line,"quote"], lines[i])
  }
}

```

Function that takes in a URL and returns a data table of quotes
```{r}
library(rvest)
library(data.table) 
pull_quotes <- function(URL) {
  webpage <- read_html(URL)
  all <- webpage %>% 
    html_nodes("blockquote") %>%
    html_text()
  #remove all text in parenthesis & brackets
  all <- gsub("\\(.*?\\)", "", all)
  all <- gsub("\\[.*?\\]", "", all)
  
  ## remove all text before "Act I" (metadata)
  all <- sub("Act I","REMOVEME", all)
  all <- gsub(".*REMOVEME", " ", all)
  
  ## remove "Act II" etc.
  #all <- gsub("Act I", " ", all)
  all <- gsub("Act III", " ", all)
  all <- gsub("Act II", " ", all)
  all <- gsub("Act IV", " ", all)
  
  # remove quotes (e.g. "Master Katara" -> Master Katara)
  all <- gsub("\\\"", "", all)
  
  ## split lines on selected punctuation
  lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–])", perl=T))
  
  ## lines with : -> character name
  ## all other lines -> most recent character's name's lines
  quotes <- data.table(name=character(), quote=character())
  
  current_line <- nrow(quotes)
  for(i in 1:length(lines)){
    if(grepl(":", lines[i])){ # make a new line
      quotes <- rbind(quotes, data.table(name = gsub("\\:|\\s", "", lines[i]), quote="")) # add character name
      current_line <- current_line + 1 #update line counter
    }
    else{
      quotes[current_line,"quote"] <- paste(quotes[current_line,"quote"], lines[i])
    }
  }
  return(quotes)
}

```

Looking at errors
```{r}
## look at 2nd episode
## trouble when sentences end on "--"

## issue when sentence doesn't end with any punctuation

test <- pull_quotes("http://atla.avatarspirit.net/transcripts.php?num=108")

```



Go through all episodes and add to quotes data table
```{r}
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
  base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
  new_url <- paste(base_url, ep_list[ep_num], sep="")
  quotes <- rbind(quotes, pull_quotes(new_url))
  print(paste("Done with Episode ", ep_list[ep_num]))
}
```

Keep only top characters
```{r}
## remove punctuation from names
#quotes[, 1] <- gsub("[[:punct:]]", "", quotes[, 1])

## frequency table of characters
#quotes[, .N, by = name][order(-N)]

## still some errors, but just dropping those lines
keep <- c("Aang", "Sokka", "Katara", "Zuko", "Toph", "Iroh")
top_quotes <- quotes[quotes$name %in% keep, ]
```


Making the first Markov model - for Aang!
```{r}
library(dplyr)
generateTrigram <- function(characterName){
  ## pulling Aang quotes
  characterQuotes <- quotes %>% filter(name == characterName)
  
  ## replacing punctuation
  characterQuotes[,2] <- trimws(gsub("\\. \\. \\. |\\. \\. \\. \\. |\\. \\. \\.", " PPAUSE ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\.", " PPERIOD ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\,", " CCOMMA ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\?", " QQUESTION ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\!", " EEXCLAMATION ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\-|\\—|\\–", " DDASH ", characterQuotes[,2]))
  
  ## removing empty rows
  characterQuotes <- characterQuotes[characterQuotes$quote != "",]
  
  
  ## allocate tons of rows now for efficiency
  totalWords <- sum(sapply(characterQuotes[,2], function(x) length(unlist(strsplit(x, " ")))))
  characterTrigram <- as.data.table(matrix(ncol = 3, nrow = totalWords))
  
  colnames(characterTrigram) <- c("w1", "w2", "w3")
  characterTrigram <- characterTrigram[, w1:=as.character(w1)]
  characterTrigram <- characterTrigram[, w2:=as.character(w2)]
  characterTrigram <- characterTrigram[, w3:=as.character(w3)]
  
  count <- 1L
  for(i in 1:nrow(characterQuotes)){
    ## split into tokens, make lowercase
    tokens <- tolower(unlist(strsplit(characterQuotes[i,2], " ", perl=T)))
    
    ## remove empty strings & \r
    tokens <- tokens[tokens != ""]
    tokens <- tokens[tokens != "\r"]
    
    ## add SSTART and EEND 
    tokens <- c("sstart", "sstart", tokens, "eend")
    
    ## loop through tokens
    for(j in 1:(length(tokens)-2)){
      set(characterTrigram, count, names(characterTrigram), list(tokens[j], tokens[j+1], tokens[j+2])) 
      count = count + 1L
    }
  }
  
  ## merge duplicate trigrams
  characterTrigram <- characterTrigram[,.N,.(w1,w2,w3)][order(-N)]
  ## remove null row
  characterTrigram <- characterTrigram[-which(is.na(characterTrigram$w1)),]
  
  return(characterTrigram)
}


```

Running trigram function for all characters
```{r}
aangTrigram <- generateTrigram("Aang")
kataraTrigram <- generateTrigram("Katara")
sokkaTrigram <- generateTrigram("Sokka")
tophTrigram <- generateTrigram("Toph")
zukoTrigram <- generateTrigram("Zuko")
irohTrigram <- generateTrigram("Iroh")

```

Using trigrams to generate next words
```{r}
inputWords <- c("i", "have")
generateWord <- function(inputWords, trigram){
  
  inputWords <- tolower(inputWords)
  
  if(length(inputWords > 1) && nrow(trigram[w1 == inputWords[1] & w2 == inputWords[2], ]) > 0){ #use trigram
    options <- trigram[w1 == inputWords[1] & w2 == inputWords[2],]
    probs <- (options$N)/sum(options$N)
    return(paste(inputWords[1], inputWords[2], sample(options$w3, 1, prob = probs)))
    
  } else if(nrow(trigram[w1 == inputWords[1], ]) > 0){ #use bigram
    options <- trigram[w1 == inputWords[1], ]
    probs <- (options$N)/sum(options$N)
    return(paste(inputWords[1], sample(options$w2, 1, prob = probs)))
    
  } else{ #use unigram
    options <- trigram[trigram$w1 == "sstart" & trigram$w2 == "sstart", ] #use words that are sentence starters
    probs <- (options$N)/sum(options$N)
    return(sample(options$w3, 1, prob = probs))
  }
  
}

## iterating
generateWord("testingg", tophTrigram)


## checking that weights are correct
# result <- c()
# for(i in 1:1000){
#   result <- c(result, sample(options$w3, 1, prob = probs))
# }
# barplot(sort(table(result), decreasing=T))
# barplot(probs)



```

Make sure to use Katz Back-off Model

