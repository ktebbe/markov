---
title: "TV dialogue markov model"
output: html_notebook
---

First we will scrape dialogue from Avatar: The Last Airbender (ATLA) from the website AvatarSpirit.net

Scripts from here - http://www.simplyscripts.com/tv_all.html

```{r}
## trying rvest library
library(rvest)
library(data.table)  
ep_list <- c(101:120, 201:220, 301:321)

url1 <- "http://atla.avatarspirit.net/transcripts.php?num=108"
webpage <- read_html(url1)

all <- webpage %>% 
  html_nodes("blockquote") %>%
  html_text()

#remove all text in parenthesis & brackets
all <- gsub("\\(.*?\\)", "", all)
all <- gsub("\\[.*?\\]", "", all)

## remove all text before "Act I" (metadata)
all <- sub("Act I","REMOVEME", all)
all <- gsub(".*REMOVEME", " ", all)

## remove "Act II" etc.
#all <- gsub("Act I", " ", all)
all <- gsub("Act III", " ", all)
all <- gsub("Act II", " ", all)
all <- gsub("Act IV", " ", all)

# remove quotes (e.g. "Master Katara" -> Master Katara)
all <- gsub("\\\"", "", all)

## split lines on selected punctuation
lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–])", perl=T))

## lines with : -> character name
## all other lines -> most recent character's name's lines
quotes <- data.table(name=character(), quote=character())

current_line <- nrow(quotes)
for(i in 1:length(lines)){
  if(grepl(":", lines[i])){ # make a new line
    quotes <- rbind(quotes, data.table(name = gsub("\\:|\\s", "", lines[i]), quote="")) # add character name
    current_line <- current_line + 1 #update line counter
  }
  else{
    quotes[current_line,"quote"] <- paste(quotes[current_line,"quote"], lines[i])
  }
}

```

Function that takes in a URL and returns a data table of quotes
```{r}
library(rvest)
library(data.table) 
pull_quotes <- function(URL) {
  webpage <- read_html(URL)
  all <- webpage %>% 
    html_nodes("blockquote") %>%
    html_text()
  #remove all text in parenthesis & brackets
  all <- gsub("\\(.*?\\)", "", all)
  all <- gsub("\\[.*?\\]", "", all)
  
  ## remove all text before "Act I" (metadata)
  all <- sub("Act I","REMOVEME", all)
  all <- gsub(".*REMOVEME", " ", all)
  
  ## remove "Act II" etc.
  #all <- gsub("Act I", " ", all)
  all <- gsub("Act III", " ", all)
  all <- gsub("Act II", " ", all)
  all <- gsub("Act IV", " ", all)
  
  # remove quotes (e.g. "Master Katara" -> Master Katara)
  all <- gsub("\\\"", "", all)
  
  ## split lines on selected punctuation
  lines <- unlist(strsplit(all, "(?<=[\\:|\\.|\\?|\\!|\\-|\\—|\\–])", perl=T))
  
  ## lines with : -> character name
  ## all other lines -> most recent character's name's lines
  quotes <- data.table(name=character(), quote=character())
  
  current_line <- nrow(quotes)
  for(i in 1:length(lines)){
    if(grepl(":", lines[i])){ # make a new line
      quotes <- rbind(quotes, data.table(name = gsub("\\:|\\s", "", lines[i]), quote="")) # add character name
      current_line <- current_line + 1 #update line counter
    }
    else{
      quotes[current_line,"quote"] <- paste(quotes[current_line,"quote"], lines[i])
    }
  }
  return(quotes)
}

```

Looking at errors
```{r}
## look at 2nd episode
## trouble when sentences end on "--"

## issue when sentence doesn't end with any punctuation

test <- pull_quotes("http://atla.avatarspirit.net/transcripts.php?num=108")

```



Go through all episodes and add to quotes data table
```{r}
ep_list <- c(101:120, 201:220, 301:321)
quotes <- data.table(name=character(), quote=character())
for(ep_num in 1:length(ep_list)){
  base_url <- "http://atla.avatarspirit.net/transcripts.php?num="
  new_url <- paste(base_url, ep_list[ep_num], sep="")
  quotes <- rbind(quotes, pull_quotes(new_url))
  print(paste("Done with Episode ", ep_list[ep_num]))
}
```

Keep only top characters
```{r}
## remove punctuation from names
#quotes[, 1] <- gsub("[[:punct:]]", "", quotes[, 1])

## frequency table of characters
#quotes[, .N, by = name][order(-N)]

## still some errors, but just dropping those lines
keep <- c("Aang", "Sokka", "Katara", "Zuko", "Toph", "Iroh")
top_quotes <- quotes[quotes$name %in% keep, ]
```


Making the first Markov model - for Aang!
```{r}
library(dplyr)
generateTrigram <- function(characterName){
  ## pulling Aang quotes
  characterQuotes <- quotes %>% filter(name == characterName)
  
  ## replacing punctuation
  characterQuotes[,2] <- trimws(gsub("\\. \\. \\. |\\. \\. \\. \\. |\\. \\. \\.", " PPAUSE ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\.", " PPERIOD ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\,", " CCOMMA ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\?", " QQUESTION ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\!", " EEXCLAMATION ", characterQuotes[,2]))
  characterQuotes[,2] <- trimws(gsub("\\-|\\—|\\–", " DDASH ", characterQuotes[,2]))
  
  ## removing empty rows
  characterQuotes <- characterQuotes[characterQuotes$quote != "",]
  
  
  ## allocate tons of rows now for efficiency
  totalWords <- sum(sapply(characterQuotes[,2], function(x) length(unlist(strsplit(x, " ")))))
  characterTrigram <- as.data.table(matrix(ncol = 3, nrow = totalWords))
  
  colnames(characterTrigram) <- c("w1", "w2", "w3")
  characterTrigram <- characterTrigram[, w1:=as.character(w1)]
  characterTrigram <- characterTrigram[, w2:=as.character(w2)]
  characterTrigram <- characterTrigram[, w3:=as.character(w3)]
  
  count <- 1L
  for(i in 1:nrow(characterQuotes)){
    ## split into tokens, make lowercase
    tokens <- tolower(unlist(strsplit(characterQuotes[i,2], " ", perl=T)))
    
    ## remove empty strings & \r
    tokens <- tokens[tokens != ""]
    tokens <- tokens[tokens != "\r"]
    
    ## add SSTART and EEND 
    tokens <- c("sstart", "sstart", tokens, "eend")
    
    ## loop through tokens
    for(j in 1:(length(tokens)-2)){
      set(characterTrigram, count, names(characterTrigram), list(tokens[j], tokens[j+1], tokens[j+2])) 
      count = count + 1L
    }
  }
  
  ## merge duplicate trigrams
  characterTrigram <- characterTrigram[,.N,.(w1,w2,w3)][order(-N)]
  ## remove null row
  characterTrigram <- characterTrigram[-which(is.na(characterTrigram$w1)),]
  
  return(characterTrigram)
}


```

Running trigram function for all characters
```{r}
aangTrigram <- generateTrigram("Aang")
kataraTrigram <- generateTrigram("Katara")
sokkaTrigram <- generateTrigram("Sokka")
tophTrigram <- generateTrigram("Toph")
zukoTrigram <- generateTrigram("Zuko")
irohTrigram <- generateTrigram("Iroh")

```

Using trigrams to generate next words
```{r}
generateWord <- function(inputWords, trigram){
  inputWords <- tolower(unlist(strsplit(inputWords, " ")))
  #inputWords <- tolower(inputWords)
  
  if(length(inputWords > 1) && nrow(trigram[w1 == inputWords[1] & w2 == inputWords[2], ]) > 0){ #use trigram
    options <- trigram[w1 == inputWords[1] & w2 == inputWords[2],]
    probs <- (options$N)/sum(options$N)
    return(paste(inputWords[1], inputWords[2], sample(options$w3, 1, prob = probs)))
    
  } else if(nrow(trigram[w1 == inputWords[1], ]) > 0){ #use bigram
    options <- trigram[w1 == inputWords[1], ]
    probs <- (options$N)/sum(options$N)
    return(paste(inputWords[1], sample(options$w2, 1, prob = probs)))
    
  } else{ #use unigram
    options <- trigram[trigram$w1 == "sstart" & trigram$w2 == "sstart", ] #use words that are sentence starters
    probs <- (options$N)/sum(options$N)
    return(sample(options$w3, 1, prob = probs))
  }
  
}

## iterating function
generateSentence <- function(sentence, trigram, duration){
    tokens <- tolower(unlist(strsplit(sentence, " "))) # split into words/punctuation
    num <- length(tokens)
    if(num > 2) { # keep only last two tokens, in case user entered more
      tokens <- c(tokens[num - 1], tokens[num])
    }
    ########
  
  for(i in 1:duration){
    num <- length(tokens)
    if(num == 1 | num == 0){ # zero or one word input
      sentence <- generateWord(tokens, trigram) # new one- or two-word sentence
    } else{ #2+ word input
      newestQuote <- unlist(strsplit(generateWord(c(tokens[num-1], tokens[num]), trigram), " "))
      
      if(length(newestQuote) == 2){ # second input word not there -> replace
        sentence <- paste(newestQuote, collapse = " ")
      } else{
        sentence <- paste(sentence, newestQuote[length(newestQuote)])
      }
    }
    
    ## check for sentence ending token
    tokens <- unlist(strsplit(sentence, " "))
    num <- length(tokens)
    if(tokens[num] == "eend"){
      sentence <- paste(tokens[-num], collapse = " ")
      return(sentence)
    }
  }
  return(sentence)
}

## change ppause, pperiod, eexclamation, qquestion, ddash, ccomma
reformat <- function(sentence){
  sentence <- gsub(" pperiod", ".", sentence)
  sentence <- gsub(" eexclamation", "!", sentence)
  sentence <- gsub(" qquestion", "?", sentence)
  sentence <- gsub(" ddash", "-", sentence)
  sentence <- gsub(" ccomma", ",", sentence)
  
  ## find start of line, tokens with sentence ending punctuation, "i" words, proper nouns
  tokens <- unlist(strsplit(sentence, " "))
  sentenceEnds <- c(0, c(which(grepl("\\.", tokens)), which(grepl("!", tokens)), which(grepl("\\?", tokens))))
  sentenceEnds <- sentenceEnds[sentenceEnds != length(tokens)] #remove last token index (if in)
  tokensToUpper <- sentenceEnds + 1
  tokensToUpper <- c(tokensToUpper, which(tokens == "i"), which(tokens == "i'll"), which(tokens == "i'd")) ## or "I" words
  tokensToUpper <- unique(tokensToUpper) ## remove duplicates
  
  for(i in 1:length(tokensToUpper)){
    index <- tokensToUpper[i]
    tokens[index] <- paste(toupper(substring(tokens[index], 1, 1)), substring(tokens[index], 2), sep="", collapse=" ")
  }
  sentence <- paste(tokens, collapse = " ")
  sentence <- gsub(" ppause ", "...", sentence)
  return(sentence)
}
```
Testing
```{r}
reformat(generateSentence("", aangTrigram, 15))

reformat(generateSentence("we're leaving", aangTrigram, 15))

## find proper nouns!!


## iroh error - Iroh : I you will find your own body flow, the switch to a better place. Eend promise you will find your own body flow, the switch to a better place. 
reformat(generateSentence("better place pperiod", irohTrigram, 15))

reformat(generateSentence("i like", irohTrigram, 20))
generateSentence("i like", irohTrigram, 20)

```

